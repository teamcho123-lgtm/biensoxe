import streamlit as st
import cv2
import numpy as np
import easyocr
import re
from ultralytics import YOLO

# ----------------- C·∫•u h√¨nh -----------------
DEFAULT_YOLO_WEIGHTS = "best.pt" 
ALLOWLIST = "0123456789ABCDEFGHIJKLMNPRSTUVXYZ-."
MAG_RATIOS = [1.0, 1.5, 2.0]
PAD_RATIO = 0.05

# Ch·ªØ c√°i h·ª£p l·ªá tr√™n bi·ªÉn s·ªë VN (lo·∫°i b·ªè I, O, Q, J, W v√¨ d·ªÖ nh·∫ßm)
VN_LETTERS = set("ABCDEFGHKLMNPRSTUVXYZ")

# Regex ƒë·ªãnh d·∫°ng bi·ªÉn s·ªë VN
PLATE_PATTERNS = [
    re.compile(r"^\d{2}[A-Z]-\d{3}\.\d{2}$"),  # 30F-441.01
    re.compile(r"^\d{2}-\d{5}$"),              # 12-34567
    re.compile(r"^\d{2}[A-Z]-\d{4}$"),         # 30F-1234
    re.compile(r"^\d{2}[A-Z]\d{5}$"),          # 30F12345
]

PROVINCE_CODES = {f"{i:02d}" for i in range(1, 100)}

# ----------------- Load Models -----------------
@st.cache_resource
def load_models(weights_path, use_gpu):
    try:
        detector = YOLO(weights_path)
        reader = easyocr.Reader(['en'], gpu=use_gpu)
        return detector, reader, None
    except Exception as e:
        return None, None, str(e)

# ----------------- X·ª≠ l√Ω ·∫£nh -----------------
def safe_crop(img, xyxy, pad_ratio=PAD_RATIO):
    h, w = img.shape[:2]
    x1, y1, x2, y2 = [int(v) for v in xyxy]
    bw, bh = max(1, x2 - x1), max(1, y2 - y1)
    pad_x, pad_y = int(bw * pad_ratio), int(bh * pad_ratio)
    xa = max(0, x1 - pad_x)
    ya = max(0, y1 - pad_y)
    xb = min(w - 1, x2 + pad_x)
    yb = min(h - 1, y2 + pad_y)
    return img[ya:yb, xa:xb].copy()

def enhance_image(img):
    """C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ·∫£nh cho OCR"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # TƒÉng t∆∞∆°ng ph·∫£n
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    
    # Kh·ª≠ nhi·ªÖu nh·∫π
    denoised = cv2.fastNlMeansDenoising(enhanced, h=7)
    
    return cv2.cvtColor(denoised, cv2.COLOR_GRAY2BGR)

def resize_for_ocr(img, min_height=60):
    """Resize ·∫£nh ƒë·ªÉ ph√π h·ª£p v·ªõi OCR"""
    h, w = img.shape[:2]
    if h < min_height:
        scale = min_height / h
        new_w = int(w * scale)
        new_h = int(h * scale)
        # Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc t·ªëi ƒëa
        if new_w > 600:
            scale = 600 / w
            new_w = 600
            new_h = int(h * scale)
        return cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
    return img

# ----------------- X·ª≠ l√Ω text -----------------
def clean_text(text):
    """L√†m s·∫°ch text OCR"""
    text = text.strip().upper().replace(" ", "")
    return "".join(c for c in text if c.isalnum() or c in "-.")

def fix_char_confusion(text, position, expected_type):
    """S·ª≠a nh·∫ßm l·∫´n k√Ω t·ª± d·ª±a tr√™n v·ªã tr√≠ v√† lo·∫°i k·ª≥ v·ªçng"""
    if not text or position >= len(text):
        return text
    
    char = text[position]
    
    if expected_type == "digit":
        # V·ªã tr√≠ c·∫ßn s·ªë: s·ª≠a O->0, I->1, S->5, Z->2, B->8
        fixes = {"O": "0", "Q": "0", "D": "0", "I": "1", "L": "1", 
                 "S": "5", "Z": "2", "B": "8"}
        return fixes.get(char, char)
    elif expected_type == "letter":
        # V·ªã tr√≠ c·∫ßn ch·ªØ: s·ª≠a 0->O, 1->I, 5->S, 2->Z, 8->B
        fixes = {"0": "O", "1": "I", "5": "S", "2": "Z", "8": "B"}
        fixed = fixes.get(char, char)
        # Ch·ªâ gi·ªØ ch·ªØ c√°i h·ª£p l·ªá tr√™n bi·ªÉn s·ªë VN
        if fixed in VN_LETTERS:
            return fixed
        return char
    return char

def normalize_plate(text):
    """Chu·∫©n h√≥a bi·ªÉn s·ªë theo ƒë·ªãnh d·∫°ng VN"""
    text = clean_text(text)
    if not text:
        return ""
    
    # Lo·∫°i b·ªè d·∫•u ph√¢n c√°ch ƒë·ªÉ ph√¢n t√≠ch
    compact = text.replace("-", "").replace(".", "")
    
    # M·∫´u: 37M00079 -> 37M-000.79 (bi·ªÉn s·ªë 2 d√≤ng)
    # T√¨m pattern: 2 s·ªë + 1 ch·ªØ + 5 s·ªë
    match = re.match(r"^(\d{2})([A-Z])(\d{5})$", compact)
    if match:
        province = match.group(1)
        letter = match.group(2)
        numbers = match.group(3)
        
        # S·ª≠a 2 s·ªë ƒë·∫ßu (m√£ t·ªânh) - ch·ªâ s·ª≠a n·∫øu th·ª±c s·ª± c·∫ßn
        province_fixed = "".join(fix_char_confusion(province, i, "digit") for i in range(len(province)))
        if not province_fixed.isdigit() or len(province_fixed) != 2:
            province_fixed = province
        
        # S·ª≠a ch·ªØ c√°i - ch·ªâ s·ª≠a n·∫øu kh√¥ng ph·∫£i ch·ªØ h·ª£p l·ªá
        if letter not in VN_LETTERS:
            letter = fix_char_confusion(letter, 0, "letter")
        if letter not in VN_LETTERS:
            return text  # Kh√¥ng th·ªÉ s·ª≠a ƒë∆∞·ª£c
        
        # S·ª≠a ph·∫ßn s·ªë - ch·ªâ s·ª≠a c√°c k√Ω t·ª± kh√¥ng ph·∫£i s·ªë
        numbers_fixed = ""
        for i, char in enumerate(numbers):
            if char.isdigit():
                numbers_fixed += char
            else:
                fixed = fix_char_confusion(numbers, i, "digit")
                if fixed.isdigit():
                    numbers_fixed += fixed
                else:
                    numbers_fixed += char  # Gi·ªØ nguy√™n n·∫øu kh√¥ng s·ª≠a ƒë∆∞·ª£c
        
        if len(numbers_fixed) == 5 and numbers_fixed.isdigit():
            return f"{province_fixed}{letter}-{numbers_fixed[:3]}.{numbers_fixed[3:]}"
    
    # M·∫´u: 30F44101 -> 30F-441.01 (bi·ªÉn s·ªë 1 d√≤ng)
    match2 = re.match(r"^(\d{2})([A-Z0-9])(\d{3,5})$", compact)
    if match2:
        province = match2.group(1)
        letter = match2.group(2)
        numbers = match2.group(3)
        
        province_fixed = "".join(fix_char_confusion(province, i, "digit") for i in range(len(province)))
        if not province_fixed.isdigit() or len(province_fixed) != 2:
            return text
        
        if letter not in VN_LETTERS:
            letter = fix_char_confusion(letter, 0, "letter")
        if letter not in VN_LETTERS:
            return text
        
        numbers_fixed = "".join(fix_char_confusion(numbers, i, "digit") for i in range(len(numbers)))
        if not numbers_fixed.isdigit():
            return text
        
        if len(numbers_fixed) == 5:
            return f"{province_fixed}{letter}-{numbers_fixed[:3]}.{numbers_fixed[3:]}"
        elif len(numbers_fixed) == 4:
            return f"{province_fixed}{letter}-{numbers_fixed}"
        elif len(numbers_fixed) == 3:
            return f"{province_fixed}{letter}-{numbers_fixed}"
    
    # M·∫´u: 12-34567 (xe m√°y)
    match3 = re.match(r"^(\d{2})(\d{5})$", compact)
    if match3:
        province = "".join(fix_char_confusion(match3.group(1), i, "digit") for i in range(2))
        numbers = "".join(fix_char_confusion(match3.group(2), i, "digit") for i in range(5))
        if province.isdigit() and numbers.isdigit():
            return f"{province}-{numbers}"
    
    return text

def score_plate(text, confidence):
    """T√≠nh ƒëi·ªÉm cho k·∫øt qu·∫£ OCR"""
    score = confidence
    text_clean = clean_text(text)
    
    # Th∆∞·ªüng ƒëi·ªÉm n·∫øu kh·ªõp ƒë·ªãnh d·∫°ng
    for pattern in PLATE_PATTERNS:
        if pattern.match(text_clean):
            score += 0.4
            break
    
    # Th∆∞·ªüng ƒëi·ªÉm n·∫øu m√£ t·ªânh h·ª£p l·ªá
    if len(text_clean) >= 2 and text_clean[:2].isdigit():
        if text_clean[:2] in PROVINCE_CODES:
            score += 0.2
    
    # Ph·∫°t n·∫øu qu√° ng·∫Øn
    if len(text_clean) < 5:
        score -= 0.3
    
    return score

# ----------------- OCR -----------------
def read_plate_ocr(img, reader):
    """ƒê·ªçc bi·ªÉn s·ªë t·ª´ ·∫£nh (ƒë∆°n gi·∫£n, ∆∞u ti√™n gi·ªØ ƒë·ªß k√Ω t·ª±)."""
    # 1) Ti·ªÅn x·ª≠ l√Ω & resize 1 l·∫ßn
    enhanced = enhance_image(img)
    img_ocr = resize_for_ocr(enhanced)

    try:
        results = reader.readtext(
            img_ocr,
            detail=1,
            allowlist=ALLOWLIST,
            paragraph=False
        )
    except Exception:
        return None, 0.0

    if not results:
        return None, 0.0

    # 2) L·ªçc & s·∫Øp x·∫øp segment theo v·ªã tr√≠ (tr√™n‚Üíd∆∞·ªõi, tr√°i‚Üíph·∫£i)
    segments = []
    for bbox, txt, conf in results:
        cleaned = clean_text(txt)
        if not cleaned:
            continue
        # bbox: 4 ƒëi·ªÉm, l·∫•y t√¢m ƒë·ªÉ s·∫Øp x·∫øp
        xs = [p[0] for p in bbox]
        ys = [p[1] for p in bbox]
        cx = float(sum(xs)) / len(xs)
        cy = float(sum(ys)) / len(ys)
        segments.append((cy, cx, cleaned, conf if conf is not None else 0.0))

    if not segments:
        return None, 0.0

    # sort by y then x ƒë·ªÉ gi·ªØ ƒë√∫ng th·ª© t·ª± 2 d√≤ng bi·ªÉn s·ªë
    segments.sort(key=lambda s: (s[0], s[1]))

    combined_text = "".join(seg[2] for seg in segments)
    avg_conf = float(np.mean([seg[3] for seg in segments])) if segments else 0.0

    normalized = normalize_plate(combined_text)
    score = score_plate(normalized, avg_conf)

    # N·∫øu chu·∫©n ho√° l√†m chu·ªói t·ªá h∆°n (ng·∫Øn h∆°n nhi·ªÅu), gi·ªØ b·∫£n g·ªëc
    if len(clean_text(normalized)) + 1 < len(clean_text(combined_text)):
        normalized = combined_text

    return normalized, avg_conf

# ----------------- Streamlit UI -----------------
st.set_page_config(
    page_title="Nh·∫≠n di·ªán bi·ªÉn s·ªë xe",
    page_icon="üöó",
    layout="wide"
)

st.title("üö¶ H·ªá Th·ªëng Nh·∫≠n Di·ªán Bi·ªÉn S·ªë Xe")
st.markdown("---")

st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh")
gpu_option = st.sidebar.checkbox("S·ª≠ d·ª•ng GPU", value=False)
conf_threshold = st.sidebar.slider("Ng∆∞·ª°ng YOLO", 0.1, 1.0, 0.5)

with st.spinner("ƒêang t·∫£i m√¥ h√¨nh..."):
    detector, reader, error_msg = load_models(DEFAULT_YOLO_WEIGHTS, gpu_option)

if error_msg:
    st.error(f"‚ùå L·ªói: {error_msg}")
    st.stop()

uploaded_file = st.file_uploader("T·∫£i l√™n ·∫£nh xe", type=['jpg', 'jpeg', 'png', 'bmp'])

if uploaded_file is not None:
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    image = cv2.imdecode(file_bytes, 1)
    
    st.subheader("üñºÔ∏è ·∫¢nh ƒê·∫ßu V√†o")
    st.image(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), use_container_width=True)
    
    if st.button("üîç Nh·∫≠n di·ªán"):
        with st.spinner("ƒêang x·ª≠ l√Ω..."):
            results = detector(image, conf=conf_threshold, verbose=False)
            
            found_plates = []
            output_image = image.copy()
            
            for result in results:
                boxes = getattr(result.boxes, "xyxy", None)
                if boxes is None:
                    continue
                
                for box in boxes.tolist():
                    x1, y1, x2, y2 = [int(v) for v in box]
                    crop = safe_crop(image, (x1, y1, x2, y2))
                    
                    if crop.size == 0:
                        continue
                    
                    # ƒê·ªçc bi·ªÉn s·ªë
                    plate_text, confidence = read_plate_ocr(crop, reader)
                    
                    if plate_text and len(plate_text) >= 5:
                        found_plates.append({
                            "text": plate_text,
                            "confidence": confidence,
                            "crop": crop,
                            "bbox": (x1, y1, x2, y2)
                        })
                        
                        # V·∫Ω l√™n ·∫£nh
                        cv2.rectangle(output_image, (x1, y1), (x2, y2), (0, 255, 0), 3)
                        cv2.putText(output_image, plate_text, (x1, max(y1 - 10, 0)),
                                 cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("‚úÖ K·∫øt Qu·∫£")
                st.image(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB), use_container_width=True)
            
            with col2:
                st.subheader("üìÑ Chi Ti·∫øt")
                if found_plates:
                    for i, plate in enumerate(found_plates):
                        st.success(f"**Bi·ªÉn s·ªë #{i+1}: {plate['text']}**")
                        st.caption(f"ƒê·ªô tin c·∫≠y: {plate['confidence']:.2%}")
                        st.image(cv2.cvtColor(plate['crop'], cv2.COLOR_BGR2RGB), 
                                width=300, caption="·∫¢nh crop")
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë n√†o.")
